Linux内核的内存管理模块，为了提高自身的扩展性，在设计层面我认为用到了下面几个方法：

* 分类
* 预取
* 专有

虽然可以细分为三种类型，但仔细观察他们的中心思想其实是一样的。用一个字来描述，那就是

> **分**

扩展性之所以会出现瓶颈是因为生产者和消费者之间的不匹配。假如能够保证生产者和消费者数量是1:1，那么就不会产生扩展性问题。然而现实中往往出现这样的不匹配。基于这个思维出发，那么能想到的一个纬度就是尽可能增加生产者来减少消费者之间的竞争。

接下来我们来看看内存管理模块是如何在这三个方面增加生产者的。

# 分类

假设我们把整个物理内存空间看成一个整体（生产者），那么面对当前系统中数以千记的进程（消费者）这个扩展性一定是很差的。那么第一个增加生产者的方式就是给内存分类。

在当前内存设计中，我能想到的分类依据有：

* NUMA
* ZONE
* 页大小

如果舍前两者是从内存的物理属性出发来分类，那么第三种则是软件设计人员创造性的增加了一种分类的方式。

内存按照NUMA,ZONE进行分类的示意图如下：

```
   node_data[0]                                                node_data[1]
   +-----------------------------+                             +-----------------------------+        
   |node_id                <---+ |                             |node_id                <---+ |        
   |   (int)                   | |                             |   (int)                   | |        
   +-----------------------------+                             +-----------------------------+    
   |node_zones[MAX_NR_ZONES]   | |    [ZONE_DMA]               |node_zones[MAX_NR_ZONES]   | |    [ZONE_DMA]       
   |   (struct zone)           | |    +---------------+        |   (struct zone)           | |    +---------------+
   |   +-------------------------+    |0              |        |   +-------------------------+    |empty          |
   |   |                       | |    |16M            |        |   |                       | |    |               |
   |   |zone_pgdat         ----+ |    +---------------+        |   |zone_pgdat         ----+ |    +---------------+
   |   |                         |                             |   |                         |        
   |   |                         |    [ZONE_DMA32]             |   |                         |    [ZONE_DMA32]        
   |   |                         |    +---------------+        |   |                         |    +---------------+   
   |   |                         |    |16M            |        |   |                         |    |3G             |   
   |   |                         |    |3G             |        |   |                         |    |4G             |   
   |   |                         |    +---------------+        |   |                         |    +---------------+   
   |   |                         |                             |   |                         |        
   |   |                         |    [ZONE_NORMAL]            |   |                         |    [ZONE_NORMAL]       
   |   |                         |    +---------------+        |   |                         |    +---------------+   
   |   |                         |    |empty          |        |   |                         |    |4G             |   
   |   |                         |    |               |        |   |                         |    |6G             |   
   +---+-------------------------+    +---------------+        +---+-------------------------+    +---------------+
```

可以看到，内存管理模块首先将内存按照numa分成了两个node。这样当有消费者需要分配/释放内存时，只需要找到相应的node。如果两个消费者需要释放存在不同node上的内存，那他们就可以同时进行。

进一步的又将每个node上的内存按照zone的属性进行了划分，原理同上。

关于node，zone的概念大家可以在[Node-Zone-Page][1]一文中找到更多的信息。

内存按照页大小进行分类的示意图如下：

```
      struct zone
      +------------------------------+      The buddy system
      |free_area[MAX_ORDER]  0...10  |
      |   (struct free_area)         |
      |   +--------------------------+
      |   |nr_free                   |  number of available pages
      |   |(unsigned long)           |  in this zone
      |   |                          |
      |   +--------------------------+
      |   |                          |           free_area[0]
      |   |free_list[MIGRATE_TYPES]  |  Order0   +-----------------------+
      |   |(struct list_head)        |  Pages    |free_list              |
      |   |                          |           |  (struct list_head)   |
      |   |                          |           +-----------------------+
      |   |                          |
      |   |                          |           free_area[1]
      |   |                          |  Order1   +-----------------------+
      |   |                          |  Pages    |free_list              |
      |   |                          |           |  (struct list_head)   |
      |   |                          |           +-----------------------+
      |   |                          |
      |   |                          |              .
      |   |                          |              .
      |   |                          |              .
      |   |                          |
      |   |                          |
      |   |                          |           free_area[10]
      |   |                          |  Order10  +-----------------------+
      |   |                          |  Pages    |free_list              |
      |   |                          |           |  (struct list_head)   |
      |   |                          |           +-----------------------+
      |   |                          |
      +---+--------------------------+
```

这个示意图将zone结构体进一步打开。其中重要的就是free_list成员。这是一个按照页大小排列的数组，不同大小的页会保存在对应大小的数组中。这样以来当需要分配内存时，我们只需要在对应的大小数组中取搜索。以此提高了扩展性。

关于free_list的概念大家也可以在[Node-Zone-Page][1]一文中找到更多的信息。

# 预取

这第二种方式是预取，直接的意思是每次要获取资源时，并不是获取所需的数量，而是获取多一些的数量来减少以后获取资源的次数。从另一个角度理解，就好比将一部分的资源单独分出来专门给某个消费者使用。

在内存管理模块总，这个方式是建立在第一种分类基础之上的。

比如有一个消费者每次都申请一定大小的内存，如果每次申请时都从free_list上分配，那么每次都会和其他需要申请内存的消费者发生竞争。但是如果我们每次申请时多申请一部分，那么竞争的次数就会大大下降。从而提高了系统的扩展性。

在内存管理中使用到这个思想的有：

* per_cpu_pageset
* slub

对于per_cpu_pageset，可以观察这个结构体中的batch字段。

```
    +------------------------------+
    |pageset                       |
    |   (struct per_cpu_pageset *) |
    |   +--------------------------+
    |   |pcp                       |
    |   |  (struct per_cpu_pages)  |
    |   |  +-----------------------+
    |   |  |count                  |
    |   |  |high                   |
    |   |  |batch                  |
    |   |  |                       |
    |   |  |lists[MIGRATE_PCPTYPES]|
    +---+--+-----------------------+
```

这个字段控制了每次需要从页分配器中获取/释放的页面个数，具体可以参考下面这两个函数。

  * __rmqueue_pcplist()。
  * free_unref_page_commit(）。

当per_cpu_pageset空时，系统是从free_list上取下batch个页面，而不是仅仅取出一个。当per_cpu_pageset满时，则是反向操作。这样就减少了对free_list的竞争。

对于slub，可以观察结构体中的oo字段。

```
    +------------------------------+
    |oo                            |
    |min                           |
    |max                           |
    |   (kmem_cache_order_objects) |
    |   +--------------------------+
    |   |order                     |
    |   |order_objects             |
    +---+--------------------------+
```

这个oo表示了每次分配一个slab时，需要的page的页数。其中计算个过程和使用分别在下面两个函数中。

  * calculate_sizes()
  * alloc_slab_page()

有兴趣的朋友可以进一步学习。

# 专有

[1]: /mm/05-Node_Zone_Page.md
